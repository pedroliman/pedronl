<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R by Pedro N. de Lima</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Pedro N. de Lima</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Mon, 22 Apr 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Factory Physics&#39; Flow Benchmarking in R</title>
      <link>/post/factory-physics-flow-benchmarking-in-r/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/factory-physics-flow-benchmarking-in-r/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://factoryphysics.com/flow-benchmarking&#34;&gt;Flow Benchmarking&lt;/a&gt; is an absolute benchmarking technique that allows one to visualize the performance limits of a manufacturing system in terms of Work in Process, Throughput and Cycle Time. This technique has been introduced in the award-winning &lt;em&gt;Factory Physics&lt;/em&gt; (FP) Book &lt;span class=&#34;citation&#34;&gt;(Hopp and Spearman &lt;a href=&#34;#ref-hopp2008factory&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt;, and is a key component of the science-based manufacturing management approach described in &lt;span class=&#34;citation&#34;&gt;(Pound, Bell, and Spearman &lt;a href=&#34;#ref-pound2014factory&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;. This post will use &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt; to allow one to quickly run this analysis using the Basic Factory Dynamics equations found in the original FP books.&lt;/p&gt;
&lt;div id=&#34;defining-fp-laws&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Defining FP Laws&lt;/h2&gt;
&lt;p&gt;The Flow Benchmarking analysis is grounded on Little’s Law (WIP = TH * CT), and utilizes three general cases as absolute benchmarks for any real manufacturing system: The &lt;strong&gt;Best Case&lt;/strong&gt;, the &lt;strong&gt;Worst Case&lt;/strong&gt; and the &lt;strong&gt;Practical Worst Case&lt;/strong&gt; .Please refer to &lt;span class=&#34;citation&#34;&gt;(Hopp and Spearman &lt;a href=&#34;#ref-hopp2008factory&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;(Pound, Bell, and Spearman &lt;a href=&#34;#ref-pound2014factory&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; for the rationale for these laws and equations.&lt;/p&gt;
&lt;p&gt;I’ll define these equations as R functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;calc_w0 = function(rb, t0) {rb * t0}

ct_best = function(t0, w, w0, rb) {ifelse(w&amp;lt;=w0,t0,w/rb)}

th_best = function(t0, w, w0, rb) {ifelse(w&amp;lt;=w0,w/t0,rb)}

ct_worst = function(w,t0){w*t0}

th_worst = function(t0){1/t0}

ct_marginal = function(t0,w,rb){t0+(w-1)/rb}

th_marginal = function(w0,w,rb){rb*w/(w0+w-1)}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In summary, these equations provide a starting point to discuss how well a manufacturing system is doing in terms of converting inventory to Throughput. The initial analysis requires two inputs. The first input is the &lt;strong&gt;Bottleneck rate (rb)&lt;/strong&gt;, which is the production rate (parts, orders / time) of the bottleneck (defined as the process center with the highest long-term utilization). The second parameter is the &lt;strong&gt;Total Raw Processing Time (t0)&lt;/strong&gt;, which is the sum of the long-term average process times of each processing center. Based on these two parameters, its possible to draw benchmarking curves for the System’s Throughput and Cycle Time as a function of its Work in Process, assuming a CONWIP control system &lt;span class=&#34;citation&#34;&gt;(SPEARMAN, WOODRUFF, and HOPP &lt;a href=&#34;#ref-Spearman1990&#34;&gt;1990&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;drawing-benchmarking-curves&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Drawing Benchmarking Curves&lt;/h2&gt;
&lt;p&gt;Once I have the basic laws of manufacturing dynamics as R functions, I’ll create a &lt;code&gt;benchmarck_flow&lt;/code&gt; function to execute the analysis. This function accepts the &lt;code&gt;rb&lt;/code&gt; and &lt;code&gt;t0&lt;/code&gt; parameters and will calculate the system’s Throughput and Cycle time as a function of the wip under different scenarios for benchmarking purposes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Defining Cycle time and Throughput functions

benchmark_flow = function(rb, t0, step = 1, wip_mult = 5) {
  
  # First, calculate wip_crit
  w0 = calc_w0(rb = rb, t0 = t0)
  
  # Then, define WIP Range to consider:
  wip = seq.int(from = 1, to = w0 * wip_mult, by = step)
  
  # Then, calculate The Best Case Variables
  Best_Cycle_Time = ct_best(t0 = t0, w = wip, w0 = w0, rb = rb)
  Best_Throughput = th_best(t0 = t0, w = wip, w0 = w0, rb = rb)
  
  best_data = data.frame(WIP = wip,
                    Throughput = Best_Throughput,
                    CycleTime = Best_Cycle_Time,
                    Scenario = &amp;quot;Best Case&amp;quot;)
  
  # Calculate the Marginal Cases:
  Marginal_Cycle_Time = ct_marginal(t0=t0,w=wip,rb=rb)
  Marginal_Throughput = th_marginal(w0=w0,w=wip,rb=rb)
  
  marginal_data = data.frame(WIP = wip,
                    Throughput = Marginal_Throughput,
                    CycleTime = Marginal_Cycle_Time,
                    Scenario = &amp;quot;Marginal&amp;quot;)
  
  # Calculate Worst Case
  worst_data = data.frame(
    WIP = wip,
    Throughput = th_worst(t0 = t0),
    CycleTime = ct_worst(w = wip, t0 = t0),
    Scenario = &amp;quot;Worst Case&amp;quot;
  )

  # Output A DataFrame with results:
  # I&amp;#39;m not including the Worst Case because it&amp;#39;s unrealistic (and messes up my cycle time plot).
  rbind(best_data, marginal_data, worst_data)
  
}

# The First Penny Fab Example:
data_benchmark = benchmark_flow(rb = 0.5, t0 = 8)

knitr::kable(head(data_benchmark))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;WIP&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Throughput&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CycleTime&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Scenario&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Best Case&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.250&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Best Case&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.375&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Best Case&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Best Case&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Best Case&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Best Case&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Ok, now I have a table with all the benchmarking results, let’s plot it!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyr)
library(ggplot2)
library(viridis)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Carregando pacotes exigidos: viridisLite&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Lets define a wrapper function for our plot:

plot_benchmarking = function(data) {
  data %&amp;gt;%
    gather(-WIP, -Scenario, key = &amp;quot;var&amp;quot;, value = &amp;quot;Value&amp;quot;) %&amp;gt;%
  ggplot(aes(x = WIP, y = Value, color = Scenario)) +
    geom_line(size = 1) +
    facet_wrap(~ var, scales = &amp;quot;free&amp;quot;, nrow = 2, ncol = 1) +
    labs(title = &amp;quot;Flow Benchmarking Plot&amp;quot;) +
    scale_color_viridis(discrete = TRUE, option = &amp;quot;D&amp;quot;) + 
    theme_bw()
}

# Then let&amp;#39;s just benchmark and plot!

plot_benchmarking(data = benchmark_flow(rb = 0.5, t0 = 8, wip_mult = 5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-22-factory-physics-flow-benchmarking-with-arena-and-r_files/figure-html/factory-physics-flow-benchmarking-cycletime-wip-throughput-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;After plotting the benchmarking curves, compare the curves with the system’s actual condition (mark an “x” indicating the system’s actual WIP, Cycle Time and Throughput), and have a productive discussion about how to improve it. Again, I suggest you to read the &lt;span class=&#34;citation&#34;&gt;(Pound, Bell, and Spearman &lt;a href=&#34;#ref-pound2014factory&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; book to understand the many uses of this plot.&lt;/p&gt;
&lt;p&gt;If you would like to perform a more detailed analysis of a complex system, it’s possible to use a Simulation Model of the actual system, and plot the results from Simulation Runs (you would see a another line on these plots). Doing this would allow you to gain predictive insight of where the system &lt;strong&gt;will be&lt;/strong&gt; if you add WIP or make improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-hopp2008factory&#34;&gt;
&lt;p&gt;Hopp, W.J., and M.L. Spearman. 2008. &lt;em&gt;Factory Physics&lt;/em&gt;. Irwin/Mcgraw-Hill Series in Operations and Decision Sciences. McGraw-Hill. &lt;a href=&#34;https://books.google.com.br/books?id=tEjkAAAACAAJ&#34;&gt;https://books.google.com.br/books?id=tEjkAAAACAAJ&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pound2014factory&#34;&gt;
&lt;p&gt;Pound, E.S., J.H. Bell, and M.L. Spearman. 2014. &lt;em&gt;Factory Physics for Managers: How Leaders Improve Performance in a Post-Lean Six Sigma World&lt;/em&gt;. McGraw-Hill Education. &lt;a href=&#34;https://books.google.com.br/books?id=B5sXAwAAQBAJ&#34;&gt;https://books.google.com.br/books?id=B5sXAwAAQBAJ&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Spearman1990&#34;&gt;
&lt;p&gt;SPEARMAN, MARK L., DAVID L. WOODRUFF, and WALLACE J. HOPP. 1990. “CONWIP: A Pull Alternative to Kanban.” &lt;em&gt;International Journal of Production Research&lt;/em&gt; 28 (5). Taylor &amp;amp; Francis: 879–94. &lt;a href=&#34;https://doi.org/10.1080/00207549008942761&#34;&gt;https://doi.org/10.1080/00207549008942761&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Discrete Event Simulation (DES) Metamodeling - Splines with R and Arena</title>
      <link>/post/des-metamodeling-splines-r-arena/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/des-metamodeling-splines-r-arena/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://link.springer.com/referenceworkentry/10.1007%2F978-1-4419-1153-7_957&#34;&gt;Simulation Metamodeling&lt;/a&gt; - building and using surrogate models that can approximate results from more complicated simulation models - is an interesting approach to analyze results from complicated, computationally expensive simulation models. Metamodels are useful because they can yield good approximations of the original simulation model response variables using less computational resources. For an introduction to Metamodeling, refer to &lt;span class=&#34;citation&#34;&gt;(Barton &lt;a href=&#34;#ref-Barton2015&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To my knowledge, no Discrete-Event Simulation (DES) software provides metamodeling capabilities, and guidance on how to actually execute metamodeling &lt;a href=&#34;https://www.google.com/search?q=discrete+event+simulation+metamodeling&amp;amp;oq=discrete+event+simulation+metamodeling&#34;&gt;is scarce&lt;/a&gt;. In this post, I’ll build a &lt;a href=&#34;https://en.wikipedia.org/wiki/Spline_(mathematics)&#34;&gt;Spline&lt;/a&gt;-based simulation metamodel. This tutorial should be useful to advanced users of &lt;a href=&#34;https://www.arenasimulation.com&#34;&gt;Arena Simulation&lt;/a&gt; who would be willing to give metamodeling a try.&lt;/p&gt;
&lt;div id=&#34;why-splines&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Why Splines?&lt;/h3&gt;
&lt;p&gt;In my &lt;a href=&#34;/post/making-sense-of-models-with-metamodels-low-order-polynomialss-with-arena-and-r/&#34;&gt;previous post&lt;/a&gt;, I briefly described the motivation for using metamodels to approximate simulation models results. Splines are among the useful techniques for metamodeling because: (i) they are relatively simple (they are piecewise-defined polynomials), and (ii) Unlike low-order polynomials, you can generally use them with a global sampling strategy &lt;span class=&#34;citation&#34;&gt;(Barton and Meckesheimer &lt;a href=&#34;#ref-Barton2006&#34;&gt;2006&lt;/a&gt;)&lt;/span&gt;, meaning you can just sample a wide range of input values of your control variable and your model will still have a decent fit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-wrangling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Wrangling&lt;/h3&gt;
&lt;p&gt;Before developing our metamodel, let’s first load the simulation data and do some data wrangling. For the details on this step, please refer to my &lt;a href=&#34;/post/making-sense-of-models-with-metamodels-low-order-polynomialss-with-arena-and-r/&#34;&gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(arena2r)
library(dplyr)
library(ggplot2)
library(readr)

sim_results = arena2r::get_simulation_results(source = &amp;quot;2019-03-metamodeling/&amp;quot;)

sim_results$BatchSize = readr::parse_number(as.character(sim_results$Scenario))

sim_results = subset(sim_results, Statistic == &amp;quot;Entity 1.NumberOut&amp;quot;)

head(sim_results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        Scenario          Statistic Replication Value BatchSize
## 51 BatchSize200 Entity 1.NumberOut           1  9200       200
## 52 BatchSize200 Entity 1.NumberOut           2  9368       200
## 53 BatchSize200 Entity 1.NumberOut           3  9322       200
## 54 BatchSize200 Entity 1.NumberOut           4  9039       200
## 55 BatchSize200 Entity 1.NumberOut           5  9255       200
## 56 BatchSize200 Entity 1.NumberOut           6  9400       200&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;trying-splines&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Trying Splines&lt;/h3&gt;
&lt;p&gt;You can build a spline model with the R’s standard linear model &lt;code&gt;lm&lt;/code&gt; function. Instead of using the standard &lt;code&gt;Y ~ X&lt;/code&gt; formula, we just have to use the &lt;code&gt;bs()&lt;/code&gt; function from the &lt;code&gt;splines&lt;/code&gt; package. Thus, our formula for our spline metamodel will be &lt;code&gt;Y ~ bs(X)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Now using Splines:

library(splines)

# Building a Spline Model:

spline_model &amp;lt;-lm(Value ~ bs(BatchSize),data = sim_results)

summary(spline_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Value ~ bs(BatchSize), data = sim_results)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -221.646  -30.896    1.011   46.969  268.354 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)     9256.49      30.15  306.99  &amp;lt; 2e-16 ***
## bs(BatchSize)1  1312.17     102.27   12.83  &amp;lt; 2e-16 ***
## bs(BatchSize)2  1042.28      88.29   11.80 1.61e-15 ***
## bs(BatchSize)3   961.00      42.95   22.38  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 96.04 on 46 degrees of freedom
## Multiple R-squared:  0.9465, Adjusted R-squared:  0.943 
## F-statistic: 271.1 on 3 and 46 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you have your &lt;code&gt;spline_model&lt;/code&gt;, you can use the &lt;code&gt;predict&lt;/code&gt; function to estimate the expected value of the response variable. Estimating what will be the Expected value of the Output variable with a Batch Size of 200 units is easy as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(spline_model, 
        newdata = data.frame(BatchSize = 200))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1 
## 9256.489&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;optimizing-with-splines&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;“Optimizing” with Splines&lt;/h3&gt;
&lt;p&gt;Now that we have a spline model that can approximate our model results, we will use this model to find an “optimal” Batch Size which maximizes our Output Variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Defining limits:
batchlims &amp;lt;- range(sim_results$BatchSize)

# Generating Test Data
batch.grid&amp;lt;-seq(from=batchlims[1], to = batchlims[2])

# Using the metamodel:
spline_data = data.frame(BatchSize = batch.grid, 
                         Value = predict(spline_model,
                                         newdata = list(BatchSize=batch.grid))
                         )

# What is the Batch Size which &amp;quot;optimizes&amp;quot; the Output?
Optimum_BatchSize &amp;lt;- spline_data$BatchSize[which.max(spline_data$Value)]

Output_Value &amp;lt;- spline_data$Value[which.max(spline_data$Value)]

Optimum_BatchSize&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 331&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The suggested batch size is 331. Is this a reasonable guess, based on our simulation runs? Let’s figure this out by plotting the simulation data, the spline function and the optimum value found.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s plot again with the optimum batch size:
ggplot(sim_results, mapping = aes(x = BatchSize, y = Value)) + 
  geom_point() + 
  stat_smooth(method = lm, formula = y ~ splines::bs(x)) +
  geom_vline(xintercept = Optimum_BatchSize) + 
  geom_text(aes(x=Optimum_BatchSize, 
                label=&amp;quot;\nOptimum Batch Size&amp;quot;, y=9700), 
                angle=90, 
                text=element_text(size=11)
            ) + 
  labs(y = &amp;quot;Output&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-14-discrete-event-simulation-metamodeling-splines-r-arena_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, definitely this is a good estimate! This plot encourages one to avoid going below 300 units, and suggests that going 350 and above is not a good idea either. The interesting pattern that the spline curve suggests is that increasing Batchsize not always increases Output, and that the output loss is not symetric.&lt;/p&gt;
&lt;p&gt;Acknowledging these non-linear relationships is one of the outcomes I value at the end of a simulation project, and I hope that metamodeling will be an useful tool to you as well. Splines are a straightforward option to interpolate results from a simulation model, but there are other options out there. Future posts might explore other alternatives such as kriging metamodels, neural nets, and other techniques.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Barton2006&#34;&gt;
&lt;p&gt;Barton, Russell R, and Martin Meckesheimer. 2006. “Metamodel-Based Simulation Optimization” 13 (06). &lt;a href=&#34;https://doi.org/10.1016/S0927-0507(06)13018-2&#34;&gt;https://doi.org/10.1016/S0927-0507(06)13018-2&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Barton2015&#34;&gt;
&lt;p&gt;Barton, Russel R. 2015. “Tutorial: Simulation Metamodeling.” In &lt;em&gt;Proceedings of the 2015 Winter Simulation Conference&lt;/em&gt;, 1765–79.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Making Sense of Simulation Models with Metamodels Part 1 - Low-Order Polynomials with Arena and R</title>
      <link>/post/making-sense-of-models-with-metamodels-low-order-polynomialss-with-arena-and-r/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/making-sense-of-models-with-metamodels-low-order-polynomialss-with-arena-and-r/</guid>
      <description>&lt;p&gt;This is part 1 of a series of posts in which I will explore the utility of using metamodels to make sense of (and possibly optimizing) simulation models.&lt;/p&gt;
&lt;p&gt;If you used simulation modeling on a real project, you might be familiar with this fictional story:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You spent long hours building and refining your simulation model (eg.: a Discrete Event Model). Hopefully, you are confident that it can yield reliable results. Now it’s time to use the model and draw recommendations. At this point, you are probably out of time, the project was delayed by successive rounds of data collection and validation. After running a few scenarios the night before the final presentation, you reach the conclusion that it is going to be hard to explain to your client that the results are highly non-linear and maybe counter-intuitive.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;making-sense-and-possibly-optimizing-models-with-metamodels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making Sense (and possibly optimizing) Models with Metamodels&lt;/h2&gt;
&lt;p&gt;The idea of building a simple model as a surrogate of a more complicated model might seem analytical overkill. However, long ago, scholars have recognized the utility of using more explicit models to synthesize simulation results, and to find optimal parameters for models with long run time. Refer to &lt;span class=&#34;citation&#34;&gt;(Kleijnen &lt;a href=&#34;#ref-Kleijnen2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;(Barton and Meckesheimer &lt;a href=&#34;#ref-Barton2006&#34;&gt;2006&lt;/a&gt;)&lt;/span&gt; for comprehensive reviews on Metamodeling for optimization.&lt;/p&gt;
&lt;p&gt;In this post, I will show you how to analyze an Arena Discrete Event Model in R using Low-Order Polynomials.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-with-arena-and-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An Example with Arena and R&lt;/h2&gt;
&lt;p&gt;In this example, the goal is to find an “ideal” batch size, so that our expected output is maximized. Setting the Batch Size “too low”, causes the production system to lose too much time in setups (a setup is required for every batch). Setting the batch size “too high” can cause starvation in other job stations. What “too low” or “too high” means is dependent on various factors, such as cycle times, setup times and other model parameters. Also, improvements in the system may cause the “ideal” batch size to change, but we can’t figure this out without a model.&lt;/p&gt;
&lt;p&gt;Although this example is simple, the underlying idea can be generalized to any case in which a response variable is concave (e.g., Total Costs, Revenue, Throughput) in respect to a decision variable, and your goal is to figure out what this relationship looks like to better manage the system.&lt;/p&gt;
&lt;p&gt;After this introduction, we are going to focus on how to create a metamodel after simulating a few scenarios with Arena.&lt;/p&gt;
&lt;div id=&#34;data-wrangling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Wrangling&lt;/h3&gt;
&lt;p&gt;The first step is obtaining a data.frame where individual observations are simulation replications, and we have one column as the dependent variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and another column as the independent variable &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, so that we can find a function &lt;span class=&#34;math inline&#34;&gt;\(y = f_{meta}(x)\)&lt;/span&gt; that will provide an aproximation of our model results. This aproximation should be usefull to explain the relationship between &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;First, I simulated all scenarios and saved their results as separate csv files. You can download the files &lt;a href=&#34;/post/2019-03-metamodeling/batchsizefiles.zip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As you can see opening these files, Arena’s output files need work to become a useful tidy dataframe. By using the package &lt;a href=&#34;arena2r.pedronl.com&#34;&gt;Arena2R&lt;/a&gt;, I can obtain my dataframe easily with the function ‘get_simulation_results’, which will read all csv files in a given path and provide a tidy data.frame with all simulation results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(arena2r)
library(dplyr)
library(ggplot2)
library(readr)

# Obtaining a dataframe compiling all simulation results stored at the &amp;quot;source&amp;quot; folder.
sim_results = arena2r::get_simulation_results(source = &amp;quot;2019-03-metamodeling/&amp;quot;)

head(sim_results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Scenario                   Statistic Replication    Value
## 1 BatchSize200 Colagem.Queue.NumberInQueue           1 9.476321
## 2 BatchSize200 Colagem.Queue.NumberInQueue           2 7.313429
## 3 BatchSize200 Colagem.Queue.NumberInQueue           3 8.647507
## 4 BatchSize200 Colagem.Queue.NumberInQueue           4 7.966887
## 5 BatchSize200 Colagem.Queue.NumberInQueue           5 9.214783
## 6 BatchSize200 Colagem.Queue.NumberInQueue           6 8.143359&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although this dataframe is a good starting point, it does not contain our independent variable (the Batch Size) as a numeric value. I coded my output files so that they will always correspond to BatchSizeXXX, wherein XXX will be a number. After some data wrangling we will be good to continue our metamodeling.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Creating a Column For The Dependent Variable, assigning it to the number in the file name:
sim_results$BatchSize = readr::parse_number(as.character(sim_results$Scenario))

# Filter only the Outcome Variable of Interest

sim_results = subset(sim_results, Statistic == &amp;quot;Entity 1.NumberOut&amp;quot;)

# Now Let&amp;#39;s view the relationship between BatchSize and Throughput:

ggplot(sim_results, mapping = aes(x = BatchSize, y = Value, color = Value)) + 
  geom_point() +
  labs(y = &amp;quot;Output&amp;quot;, color = &amp;quot;Output&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-09-making-sense-of-models-with-metamodels-low-order-polynomials-with-arena-and-r_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows us important lessons about &lt;em&gt;non-linearity&lt;/em&gt;. Clearly, the output variable has a non-linear relationship with Batch Size. The tricky implication is that if you decided to sample only values of BatchSize &amp;gt; 300, you might reach the conclusion that increasing Batch Size has little impact on Output, and this impact is likely negative. Conversely, if you sample only BatchSize &amp;lt; 300, you would reach the opposite conclusion.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;drawing-curves-revealing-non-linear-patterns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Drawing Curves, Revealing Non-Linear Patterns&lt;/h2&gt;
&lt;p&gt;If you could draw a curve explaining the relationship between BatchSize and the Output Variable, what would this curve look like? That’s where polynomial metamodels in.&lt;/p&gt;
&lt;p&gt;You can find documentation about polynomial regression in R &lt;a href=&#34;https://www.r-bloggers.com/fitting-polynomial-regression-in-r/&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://medium.com/wwblog/polynomial-regression-in-r-c377f18d6efa&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.theanalysisfactor.com/r-tutorial-4/&#34;&gt;here&lt;/a&gt;. Put simply, regression modeling can be seen as drawing lines (or maybe curves) with the purpose of revealing the existence of relationships between variables. In our case, we will first use a polynomial function in the form $y = a + bx + cx^2 $ that will be useful to picture the non-linear relationship between BatchSize and the Output Variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(sim_results, mapping = aes(x = BatchSize, y = Value)) + 
  geom_point() + 
  stat_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x + I(x^2), size = 1) + 
  labs(y = &amp;quot;Output&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-09-making-sense-of-models-with-metamodels-low-order-polynomials-with-arena-and-r_files/figure-html/second-order-polynomial-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;optimizing-with-a-quadratic-metamodel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;“Optimizing” with a Quadratic Metamodel&lt;/h3&gt;
&lt;p&gt;Since our model is quadratic, we can do some calculus to find the point in which the output peaks:&lt;/p&gt;
&lt;p&gt;Since our function is clearly concave down, we can use simple calculus to find the BatchSize Value that maximizes the Output:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{opt} = \arg\max \ \  ax^2 + bx + c \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can find the optimal point by taking the first derivative:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y&amp;#39; = 2ax + b\]&lt;/span&gt;
Since we know our model is concave down, we know that when the first derivative reaches 0, we will be at its maximum value.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[0 = 2ax_{opt} + b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{opt} = -b / 2a\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now that we have a formula, let’s calculate the optimum batch size (based on our metamodel):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quadratic_model = lm(formula = Value ~ BatchSize + I(BatchSize^2), data = sim_results)

## Since our Model is Quadratic, we can derive a formula for the maximum, based on our results

Optimum_BatchSize = - quadratic_model$coefficients[2] / (2 * quadratic_model$coefficients[3])

Optimum_BatchSize&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BatchSize 
##  342.8003&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Does it make sense?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(sim_results, mapping = aes(x = BatchSize, y = Value)) + 
  geom_point() + 
  stat_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x + I(x^2), size = 1) +
  geom_vline(xintercept = Optimum_BatchSize) + 
  geom_text(aes(x=Optimum_BatchSize, label=&amp;quot;\nOptimum Batch Size&amp;quot;, y=9700), angle=90, text=element_text(size=11)) + 
  labs(y = &amp;quot;Output&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-09-making-sense-of-models-with-metamodels-low-order-polynomials-with-arena-and-r_files/figure-html/second-order-polynomial-with-optimum-value-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;caveats&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Caveats&lt;/h3&gt;
&lt;p&gt;There are a few caveats you should be aware of when using polynomial metamodels, and I’m citing only two of them here:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Use only low-order polynomials.&lt;/strong&gt; First, if you try a higher order polynomial (for instance, one that includes &lt;span class=&#34;math inline&#34;&gt;\(x^5\)&lt;/span&gt;), you will likely end up with an overfitted model. Try that and see that for yourself.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Avoid using them “Globally”&lt;/strong&gt;: You should avoid using low-order polynomials globally simply because they will become inacurate as you expand the sampling space. Look at the figure above. When Batch Size = 350, the quadratic model over-estimates the Output. There’s a workaround this called “Splines” which will be explored on another post, and there are better options (such as Kriging / Gaussian processes, Neural Nets, etc.).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Using low-order polynomials is a relatively straightforward option you can use to explore and visualize non-linear relationships between decision variables and outcome variables. However, simple polynomial models are limited, and more advanced techniques are available (including Splines, Gaussian Processes, and Neural Nets). The good news is that you can easily find documentation about these techniques in R. Once you have the data, putting together a metamodel in R is usually only a few keystrokes away. In future posts, I will continue to explore increasingly complex metamodels, but keep in mind that the goal should not be to add complexity to the analysis “just because we can”, but to add interpretability and meaning to our results.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Barton2006&#34;&gt;
&lt;p&gt;Barton, Russell R, and Martin Meckesheimer. 2006. “Metamodel-Based Simulation Optimization” 13 (06). &lt;a href=&#34;https://doi.org/10.1016/S0927-0507(06)13018-2&#34;&gt;https://doi.org/10.1016/S0927-0507(06)13018-2&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Kleijnen2017&#34;&gt;
&lt;p&gt;Kleijnen, Jack P C. 2017. “Regression and Kriging metamodels with their experimental designs in simulation : A review.” &lt;em&gt;European Journal of Operational Research&lt;/em&gt; 256 (1). Elsevier B.V.: 1–16. &lt;a href=&#34;https://doi.org/10.1016/j.ejor.2016.06.041&#34;&gt;https://doi.org/10.1016/j.ejor.2016.06.041&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Previsão de Séries Temporais com o R</title>
      <link>/post/previsao-de-series-temporais-com-o-r/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/previsao-de-series-temporais-com-o-r/</guid>
      <description>&lt;p&gt;Este arquivo foi utilizado como arquivo de apoio à aulas ministradas sobre previsão de demanda utilizando o R. Para um tramento mais aprofundado sobre o tema, recorrer ao excelente livro &lt;a href=&#34;https://otexts.org/fpp2/&#34;&gt;Forecating: Principles and Practice&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Este post possui uma apresentação relacionada &lt;a href=&#34;/files/slides/previsao-r/&#34;&gt;neste link&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;sobre-o-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sobre o R&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;O R é um ambiente de computação estatística, com mais de 13 mil pacotes publicados.&lt;/li&gt;
&lt;li&gt;Cada um destes pacotes tem um fim específico. Neste curso, utilizaremos principalmente as bibliotecas ‘forecast’ e o fpp2. Ambos os pacotes são utlizados no livro &lt;a href=&#34;https://otexts.org/fpp2/&#34;&gt;Forecating: Principles and Practice&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;passos-para-realizar-previsoes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Passos para Realizar Previsões&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Faça um gráfico dos dados;&lt;/li&gt;
&lt;li&gt;Selecione uma função para a previsão;&lt;/li&gt;
&lt;li&gt;Estime os parâmetros da função;&lt;/li&gt;
&lt;li&gt;Avalie a Qualidade do modelo de previsão;&lt;/li&gt;
&lt;li&gt;Selecione e implemente o melhor modelo encontrado.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;instalando-bibliotecas-no-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Instalando Bibliotecas no R&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Instale E carregue as bibliotecas que iremos utilizar nesta aula rodando estes comandos:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bibliotecas = c(&amp;quot;forecast&amp;quot;, &amp;quot;fpp2&amp;quot;, &amp;quot;readxl&amp;quot;)

install.packages(bibliotecas)

# Caso encontre algum erro, rode o install packages separadamente para cada biblioteca:
install.packages(&amp;quot;forecast&amp;quot;)
install.packages(&amp;quot;fpp2&amp;quot;)
install.packages(&amp;quot;readxl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Antes de começar, carregue as bibliotecas:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(forecast)
library(fpp2)
library(readxl)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;trabalhando-com-a-primeira-serie&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Trabalhando com a Primeira Série&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observe as série gold:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A série temporal &amp;quot;gold&amp;quot; foi carregada pela biblioteca forecast.
autoplot(gold)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;padroes-em-series-temporais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Padrões em séries temporais&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tendência: Os dados possuem uma tendência geral de aumento ou queda (exemplo: Crescimento da população).&lt;/li&gt;
&lt;li&gt;Sazonalidade: Os dados se comportam de modo similar, obedecendo padrões com &lt;strong&gt;durações fixas&lt;/strong&gt; (exemplo: venda de ovos de páscoa).&lt;/li&gt;
&lt;li&gt;Ciclicidade: A série possui um comportamento variando em ciclos, porém &lt;strong&gt;sem duração fixa&lt;/strong&gt; (exemplo: ciclos econômicos.).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;observando-outras-series-temporais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observando outras series temporais&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Produção de Lâ na Austrália
autoplot(woolyrnq) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;observando-outras-series-temporais-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observando outras series temporais&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Produção de Gás na Austrália
autoplot(gas) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;observando-o-a-sazonalidade-das-series&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observando o a Sazonalidade das Séries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A função frequency determina a frequência da série. 
# Para dados sazonais, irá definir o período dominante da sazonalidade, 
# e para dados em ciclos, a duração média dos ciclos.
frequency(gas) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;observando-graficos-sazonais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observando Gráficos Sazonais&lt;/h2&gt;
&lt;p&gt;Observando a série temporal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Produção de Gás na Austrália
autoplot(a10) + ylab(&amp;quot;Demanda Anti-Diabeticos&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Observando um gráfico sazonal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggseasonplot(a10) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Observando um gráfico sazonal “polar”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggseasonplot(a10, polar = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Observando a Venda de Cerveja:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer &amp;lt;- window(ausbeer, start = 1992)
autoplot(beer) + ylab(&amp;quot;Venda de Cerveja&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Observando a Venda de Cerveja e sua Sazonalidade:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggseasonplot(beer) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Mais uma forma de visualizar a demanda sazonal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggsubseriesplot(beer)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;criando-objetos-ts-para-series-temporais-a-partir-de-dados-reais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Criando Objetos ‘ts’ para Séries Temporais a partir de dados reais&lt;/h2&gt;
&lt;p&gt;Para manipular séries temporais no R, é interessante criar objetos do tipo ‘ts’. Podemos criar objetos a partir de arquivos do excel, csv, bases de dados, ou mesmo APIs públicas.&lt;/p&gt;
&lt;p&gt;Podemos utilizar a biblioteca ‘readxl’ para ler arquivos do excel. Obtenha &lt;a href=&#34;/post/2018-10-10-previsao-serie-temporais/VendasCarros.xlsx&#34;&gt;aqui o arquivo de dados VendasCarros.xlsx&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readxl)
dados_excel = readxl::read_xlsx(path = &amp;quot;2018-10-10-previsao-serie-temporais/VendasCarros.xlsx&amp;quot;, sheet = &amp;quot;Dados&amp;quot;)
head(dados_excel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##     Ano   Mês VendasCarros VendasCarrosAux
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;
## 1  2018     1         2493            2486
## 2  2018     2         2875            3003
## 3  2018     3         3504            3454
## 4  2018     4         3786            3665
## 5  2018     5         4094            4353
## 6  2018     6         4994            4842&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transformando-um-data-frame-em-uma-serie-temporal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transformando um Data Frame em uma Série Temporal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Para trabalhar com séries temporais, iremos transformar esta tabela:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ts_vendas = ts(data = dados_excel$VendasCarros, start = c(2018,1),frequency = 12)
ts_vendas&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
## 2018 2493 2875 3504 3786 4094 4994 4910 5575 5839 6202 6833 7382
## 2019 2470 3059 3537 4003 4110 4516 5364 5854 5752 6089 7025 7801
## 2020 2473 2884 3328 3689 4133 4932 5097 5397 6205 6374 6697 8024&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Agora que temos uma série temporal, vamos plotar:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecast::autoplot(ts_vendas)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;previsoes-com-modelos-de-suavizacao-exponencial&#34; class=&#34;section level1&#34; data-background=&#34;imgs/background-1.jpg&#34; data-background-size=&#34;cover&#34;&gt;
&lt;h1&gt;Previsões com Modelos de Suavização Exponencial&lt;/h1&gt;
&lt;div id=&#34;suavizacao-exponencial-simples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Suavização Exponencial Simples&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Método da média simples: Leva em consideração todos os períodos;&lt;/li&gt;
&lt;li&gt;Método “Naive”: Leva em consideração apenas o último período;&lt;/li&gt;
&lt;li&gt;Método da Suavização Exponencial: Leva em consideração a demanda observada nos períodos anteriores, porém faz com que o impacto dos períodos anteriores caia progressivamente.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notação da Previsão: &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{t+h|t}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Previsão para a demanda &lt;span class=&#34;math inline&#34;&gt;\(y_{t+h}\)&lt;/span&gt;, considerando dados disponiveis até &lt;span class=&#34;math inline&#34;&gt;\(y_{t}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Equação da Previsão:
&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{t+h|t} = \alpha y_{t} + \alpha(1-\alpha)y_{t-1} + \alpha(1-\alpha)^2y_{t-2} + ... \ para \  0 \leq \alpha \leq 1\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modelo-de-suavizacao-exponencial-simples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelo de Suavização Exponencial Simples&lt;/h2&gt;
&lt;p&gt;Previsão:
&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{t+h|t} = l_t\]&lt;/span&gt;
Nível:
&lt;span class=&#34;math display&#34;&gt;\[l_t = \alpha y_t + (1-\alpha)l_{t-1}\]&lt;/span&gt;
O valor &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; é obtido minimizando os erros ao rodar o modelo em um set de teste.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimando-o-modelo-com-o-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimando o Modelo com o R&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A função ‘ses’ (Simple Exponetial Smoothing) estima um modelo de suavização exponencial simples:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dados_petroleo = window(oil, start= 1996)
previsao_petroleo = ses(dados_petroleo, h = 5) # Previsao para os próximos 5 anos
summary(previsao_petroleo)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Forecast method: Simple exponential smoothing
## 
## Model Information:
## Simple exponential smoothing 
## 
## Call:
##  ses(y = dados_petroleo, h = 5) 
## 
##   Smoothing parameters:
##     alpha = 0.8339 
## 
##   Initial states:
##     l = 446.5868 
## 
##   sigma:  29.8282
## 
##      AIC     AICc      BIC 
## 178.1430 179.8573 180.8141 
## 
## Error measures:
##                    ME     RMSE     MAE      MPE     MAPE      MASE
## Training set 6.401975 28.12234 22.2587 1.097574 4.610635 0.9256774
##                     ACF1
## Training set -0.03377748
## 
## Forecasts:
##      Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
## 2014       542.6806 504.4541 580.9070 484.2183 601.1429
## 2015       542.6806 492.9073 592.4539 466.5589 618.8023
## 2016       542.6806 483.5747 601.7864 452.2860 633.0752
## 2017       542.6806 475.5269 609.8343 439.9778 645.3834
## 2018       542.6806 468.3452 617.0159 428.9945 656.3667&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Visualizando a Previsão:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;autoplot(previsao_petroleo)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modelo-de-suavizacao-exponencial-com-tendencia-linear---holt&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelo de Suavização Exponencial com Tendência Linear - Holt&lt;/h2&gt;
&lt;p&gt;Previsão:
&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{t+h|t} = l_t + h b_t\]&lt;/span&gt;
Nível:
&lt;span class=&#34;math display&#34;&gt;\[l_t = \alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1})\]&lt;/span&gt;
Tendência:
&lt;span class=&#34;math display&#34;&gt;\[b_t = \beta *(l_t-l_{t-1}) + (1-\beta)b_{t-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimando-o-modelo-com-o-r-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimando o Modelo com o R&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A função ‘holt’ (Simple Exponetial Smoothing) estima o modelo de Holt (que considera a tendência):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;previsao_petroleo_holt = holt(dados_petroleo, h = 5) # Previsao para os próximos 5 anos
autoplot(previsao_petroleo_holt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Também podemos observar os parâmetros estimados para o modelo:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(previsao_petroleo_holt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Forecast method: Holt&amp;#39;s method
## 
## Model Information:
## Holt&amp;#39;s method 
## 
## Call:
##  holt(y = dados_petroleo, h = 5) 
## 
##   Smoothing parameters:
##     alpha = 1e-04 
##     beta  = 1e-04 
## 
##   Initial states:
##     l = 428.4833 
##     b = 5.5771 
## 
##   sigma:  27.8684
## 
##      AIC     AICc      BIC 
## 177.2927 182.2927 181.7446 
## 
## Error measures:
##                      ME     RMSE      MAE        MPE     MAPE      MASE
## Training set -0.2851768 24.57757 20.53231 -0.3285466 4.337459 0.8538816
##                   ACF1
## Training set 0.3429178
## 
## Forecasts:
##      Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
## 2014       534.4382 498.7234 570.1529 479.8172 589.0591
## 2015       540.0148 504.3000 575.7295 485.3938 594.6357
## 2016       545.5913 509.8766 581.3061 490.9704 600.2123
## 2017       551.1679 515.4532 586.8827 496.5469 605.7889
## 2018       556.7445 521.0298 592.4592 502.1235 611.3655&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modelo-de-holt-com-damp&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelo de Holt com “Damp”&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Podemos utilizar o modelo Holt com “Damp”, pressupondo que o crescimento não será linear no longo prazo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Previsão:
&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{t+h|t} = l_t + (\phi+\phi^2+...+\phi^h) b_t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Nível:
&lt;span class=&#34;math display&#34;&gt;\[l_t = \alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Tendência:
&lt;span class=&#34;math display&#34;&gt;\[b_t = \beta *(l_t-l_{t-1}) + (1-\beta) \phi b_{t-1}\]&lt;/span&gt;
O parâmetro &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; é entre 0 e 1. Se o parâmetro for igual a 1, o crescimento será linear.&lt;/p&gt;
&lt;p&gt;Utilizando o Modelo de Holt com “Damp”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;previsao_petroleo_holt = holt(dados_petroleo, h = 15, PI = F)
previsao_petroleo_holt_damp = holt(dados_petroleo, h = 15, damped = T, PI = F) # Previsao para os próximos 5 anos
autoplot(dados_petroleo) + 
  autolayer(previsao_petroleo_holt, series=&amp;quot;Holt Linear&amp;quot;) + 
  autolayer(previsao_petroleo_holt_damp, series=&amp;quot;Holt com Damp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modelo-de-suavizacao-exponencial-com-tendencia-e-sazonalidade---holt-winters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelo de Suavização Exponencial com Tendência e Sazonalidade - Holt-Winters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Método Aditivo: Adequado quando a amplitude dos ciclos de sazonalidade não está correlacionada ao tempo.&lt;/li&gt;
&lt;li&gt;Método Multiplicativo: Adequado quando a amplitude dos ciclos de sazonalidade está correlacionadao ao tempo.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;modelo-holt-winters-aditivo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelo Holt-Winters Aditivo&lt;/h2&gt;
&lt;p&gt;Previsão:
&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{t+h|t} = l_t + hb_t + s_{t-m+h_m^+}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Nível:
&lt;span class=&#34;math display&#34;&gt;\[l_t = \alpha (y_t-s_{t-m}) + (1-\alpha)(l_{t-1}+b_{t-1})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Tendência:
&lt;span class=&#34;math display&#34;&gt;\[b_t = \beta *(l_t-l_{t-1}) + (1-\beta) b_{t-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Sazonalidade:
&lt;span class=&#34;math display&#34;&gt;\[b_t = \gamma(y_t - l_{t-1 - b_{t-1}}) + (1-\gamma)s_{t-m} \]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(s_{t-m+h_m^+}\)&lt;/span&gt;: componente de sazonalidade do último ano de dados disponíveis.
&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;: Período de sazonalidade.
A média do componente de sazonalidade tende a zero.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modelo-holt-winters-multiplicatio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelo Holt-Winters Multiplicatio&lt;/h2&gt;
&lt;p&gt;Previsão:
&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{t+h|t} = (l_t + hb_t) s_{t-m+h_m^+}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Nível:
&lt;span class=&#34;math display&#34;&gt;\[l_t = \alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Tendência:
&lt;span class=&#34;math display&#34;&gt;\[b_t = \beta *(l_t-l_{t-1}) + (1-\beta) b_{t-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Sazonalidade:
&lt;span class=&#34;math display&#34;&gt;\[b_t = \gamma  \frac{y_t}{l_{t-1} + b_{t-1}} + (1-\gamma)s_{t-m} \]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(s_{t-m+h_m^+}\)&lt;/span&gt;: componente de sazonalidade do último ano de dados disponíveis.
&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;: Período de sazonalidade.
A média do componente de sazonalidade tende a 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exemplo---holt-winters-aditivo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exemplo - Holt-Winters Aditivo&lt;/h2&gt;
&lt;p&gt;Relembrando a série de anti-glicêmicos.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Produção de Gás na Austrália
autoplot(a10) + ylab(&amp;quot;Demanda AntiDiabeticos&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Realizando a Previsão:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Produção de Gás na Austrália
previsao_anti_diab_aditivo = hw(a10, seasonal = &amp;quot;additive&amp;quot;, PI= F)
previsao_anti_diab_multiplicativo = hw(a10, seasonal = &amp;quot;multiplicative&amp;quot;, PI = F)
autoplot(a10) + ylab(&amp;quot;Demanda de Remédios&amp;quot;) +
  autolayer(previsao_anti_diab_aditivo, series=&amp;quot;HW Add.&amp;quot;) + 
  autolayer(previsao_anti_diab_multiplicativo, series=&amp;quot;HW Mult.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;desafio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Desafio:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Colete dados de demanda de diferentes produts em sua empresa;&lt;/li&gt;
&lt;li&gt;Verifique quais são as técnicas de previsão aplicadas a estes produtos;&lt;/li&gt;
&lt;li&gt;Identifique se há ou não tendência e sazonalidade;&lt;/li&gt;
&lt;li&gt;Aplique os métodos aprendidos;&lt;/li&gt;
&lt;li&gt;Proponha um modelo de previsão novo;&lt;/li&gt;
&lt;li&gt;Compare a acurácia do novo modelo em relação ao que existe atualmente na empresa.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;arima&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ARIMA&lt;/h1&gt;
&lt;p&gt;O modelo ARIMA não será coberto nesta aula, porém a biblioteca forecast possui uma função para estimar modelos Arima de modo automático.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelo_arima = forecast::auto.arima(a10)

autoplot(forecast(modelo_arima))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mais-aspectos-tecnicos&#34; class=&#34;section level1&#34; data-background=&#34;imgs/background-1.jpg&#34; data-background-size=&#34;cover&#34;&gt;
&lt;h1&gt;Mais Aspectos Técnicos&lt;/h1&gt;
&lt;div id=&#34;o-modelo-naive&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;O modelo “Naive”&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;O modelo “naive” simplesmente pressupõe que o futuro repetirá o passado, logo a previsão é correspondente ao último valor observado.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;previsao = naive(oil)
autoplot(oil, series=&amp;quot;Dados&amp;quot;) + 
  xlab(&amp;quot;Ano&amp;quot;) +
  autolayer(fitted(previsao), series = &amp;quot;Previsao&amp;quot;) + 
  ggtitle(&amp;quot;Produção de Petróleo na Arábia Saudita&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;observando-os-erros&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observando os Erros&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Os erros também podem ser plotados. Espera-se que os erros sejam “white noise”. Se isso é verdade, é provável que o modelo tenha captado toda a informação disponível nos dados.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;autoplot(residuals(previsao))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pressupostos-sobre-os-erros&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pressupostos sobre os Erros&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Os erros deveriam ser não-correlacionados;&lt;/li&gt;
&lt;li&gt;Os erros devem ter média zero;
Propriedades úteis:&lt;/li&gt;
&lt;li&gt;Variância Constante;&lt;/li&gt;
&lt;li&gt;São normalmente distribuídos.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;verificando-pressupostos-sobre-os-erros&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Verificando Pressupostos sobre os Erros&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A função ‘checkresiduals’ verifica os pressupostos indicados anteriormente. Espera-se que o resultado do p-valor do Ljung-box seja acima de 0.05, indicando que os erros não são correlacionados.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;checkresiduals(previsao)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Ljung-Box test
## 
## data:  Residuals from Naive method
## Q* = 11.814, df = 9.8, p-value = 0.2824
## 
## Model df: 0.   Total lags used: 9.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;o-que-fazer-se-os-erros-nao-forem-normais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;O que fazer se os erros não forem normais?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ainda assim, as previsões podem ser boas e podem ser utilizadas, porém os intervalos de predição podem ser muito justos ou amplos em função deste problema.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;training-and-test-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Training and Test Sets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Traning Set: Parte dos dados que você utiliza para construir o modelo.&lt;/li&gt;
&lt;li&gt;Test Set: Parte dos dados que você utiliza para testar o modelo.&lt;/li&gt;
&lt;li&gt;O test set não pode ser usado para calcular a previsão.&lt;/li&gt;
&lt;li&gt;Um modelo que se ajusta bem aos dados de treinamento não necessáriamente terá uma boa previsão;&lt;/li&gt;
&lt;li&gt;É comum construirmos um modelo altamente complexo que possui poucos erros nos dados de treinamento, porém gera péssimas previsões. Isto é chamado de &lt;strong&gt;overfitting&lt;/strong&gt;, e deve ser evitado.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;medidas-de-acuracia-da-previsao&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Medidas de Acurácia da Previsão&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Mean Absolute Error: &lt;span class=&#34;math inline&#34;&gt;\(MAE = avg(|e_t|)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Mean Square Error: &lt;span class=&#34;math inline&#34;&gt;\(MAE = avg(|e_t^2|)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Mean Absolute Percentage Error: &lt;span class=&#34;math inline&#34;&gt;\(MAPE = 100 * avg(|e_t/y_t|)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Mean Absolute Scaled Error: &lt;span class=&#34;math inline&#34;&gt;\(MASE = MAE / Q\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exemplo-com-um-modelo-naive&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exemplo com um Modelo Naive&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Separamos o modelo em duas partes, e geramos um modelo naive para ilustrar este ponto:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;treinamento = window(oil, end=2003)
teste = window(oil, start= 2004)
previsao = naive(treinamento,h = 10) # h = Número de períodos a prever
autoplot(previsao) + 
  ylab(&amp;quot;Vendade Petróleo&amp;quot;) + 
  autolayer(teste, series = &amp;quot;Dados de Teste&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-10-previsao-de-series-temporais-com-o-r_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;o-comando-accuracy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;O Comando Accuracy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Usar o Comando Accuracy para observar o modelo:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;accuracy(previsao, teste)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    ME     RMSE      MAE      MPE      MAPE      MASE
## Training set  9.87358 52.56156 39.42504 2.506565 12.570647 1.0000000
## Test set     21.60250 35.09832 29.97666 3.963914  5.777875 0.7603458
##                   ACF1 Theil&amp;#39;s U
## Training set 0.1801528        NA
## Test set     0.4029519  1.184862&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;obtendo-mais-series-de-dados-reais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Obtendo Mais Séries de Dados reais:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;O agregador de dados &lt;a href=&#34;https://www.quandl.com/&#34;&gt;Quandl&lt;/a&gt; possui milhares de séries temporais disponíveis diretamente no R, pela biblioteca Quandl.&lt;/li&gt;
&lt;li&gt;Exemplo: obtendo a série do índice Bovespa&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Quandl)
ts_bovespa = Quandl(&amp;quot;BCB/7&amp;quot;, type = &amp;quot;ts&amp;quot;)
autoplot(ts_bovespa)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Arena2R - An R Package for Arena Simulation Users</title>
      <link>/post/arena2r-package-tutorial/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/arena2r-package-tutorial/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arenasimulation.com&#34;&gt;Arena Simulation&lt;/a&gt; is a well-known Discrete Event Simulation Software. However, if you are a power user you might want to extend your analysis beyond what Arena’s Process Analyzer offers. In this tutorial, I’ll guide you through the main functions of Arena2R package.&lt;/p&gt;
&lt;p&gt;If you’re not an R user, fear not! Arena2R comes with an app you can use to explore your Arena Simulation data. All you’ll have to do is to Install R and R Studio, and run two commands in your R console.&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;You can install arena2r from CRAN with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;arena2r&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, load the package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(arena2r)
## Warning: package &amp;#39;arena2r&amp;#39; was built under R version 3.5.2
library(dplyr)
## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.2
## 
## Attaching package: &amp;#39;dplyr&amp;#39;
## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag
## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-arena-report-database&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exporting Arena Report Database&lt;/h2&gt;
&lt;p&gt;This is a basic example which shows you how to get your Arena results quickly into R. The basic idea is to run different scenarios and save each of them to a separate csv file. (Yes, you could use Process Analyzer (PAN) to run all scenarios, but to my knowledge, there’s no way to get your data out of the PAN easily).&lt;/p&gt;
&lt;p&gt;Follow these steps to get Arena simulation results to R:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run your model with &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; replications. Do not change the number of replications between scenarios.&lt;/li&gt;
&lt;li&gt;For each scenario, save a csv with simulation results clicking on “Tools &amp;gt; ReportDatabase &amp;gt; Export Summary Statistics to CSV File”. Use the standard options. If Arena throws an error, then you’ll have to figure out how to get your results into a csv file. Sometimes it’s necessary to save the report database as a *.mdb file before generating the csv file.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-shiny-app&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the Shiny App&lt;/h2&gt;
&lt;p&gt;If you’re not familiar to R, you can run this command on R Console and use the example app.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
runArenaApp()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After running this command, the app screen will pop up. You can upload your csv files and play around with the Confidence Interval and Scatter Plots.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-package-with-an-r-script&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the Package with an R Script&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Open a new .R file, and run the following code:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load the library:

library(arena2r)

# Define the path to your folder with Arena csv files. In my case, it&amp;#39;s here:

my_path = &amp;quot;../../../arena2r/inst/Arena14/&amp;quot;

# Then, get a tidy results data.frame out of your files!
results = arena2r::get_simulation_results(my_path)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also play around with the arena_results dataset included in the package. To use it, follow these steps:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
library(arena2r)

# Load the example dataset:
data(&amp;quot;arena_results&amp;quot;)

# Let&amp;#39;s call it results
results = arena_results

knitr::kable(head(results))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Scenario&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Replication&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;233&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;247&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;239&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;261&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;264&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;266&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;After these steps, now you have a tidy data.frame with your results. Let’s get into possible visualizations. Usually, you’ll be interested in the mean confidence interval for some response variable, across scenarios.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# Plot a Statistic confidence interval across scenarios for a response variable.

arena2r::plot_confint(sim_results = results, response_variable = &amp;quot;Entity 1.NumberOut&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-27-arena2r-package-tutorial_files/figure-html/arena2r-confidence-interval-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s explore the relationship between two variables, across scenarios and replications:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# Now let&amp;#39;s plot analyse the relationship between two variables:

arena2r::plot_scatter(sim_results = results, x_variable = &amp;quot;Entity 1.NumberIn&amp;quot;, y_variable = &amp;quot;Entity 1.NumberOut&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-27-arena2r-package-tutorial_files/figure-html/arena2r-scatter-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s go a bit deeper and leverage ggplot2 to create a plot faceted by Scenario:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# If you use ggplot and you want to get more customized plots, I suggest you to spread your data.frame:

wide_results = results %&amp;gt;%
    tidyr::spread(Statistic, Value)

# Recreating my plot with ggplot, now loking at Resource Utilization:

p = ggplot(data = wide_results, mapping = aes(x = `Resource 1.Utilization`, y = `Entity 1.NumberOut`, color = Scenario)) + geom_point() + facet_wrap(~Scenario)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-27-arena2r-package-tutorial_files/figure-html/arena2r-custom-ggplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally, let’s summarise every statistic across all scenarios.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
statistics_summary = arena2r::get_statistics_summary(sim_results = results, confidence = 0.95)

knitr::kable(head(statistics_summary[,1:6]))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Scenario&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SD&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Min&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Max&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberIn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;241.03333&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15.773140&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;209.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;276.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NumberOut&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;225.13333&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.735870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;205.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;240.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.NVATime&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.OtherTime&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.TotalTime&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.15272&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.850762&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.161059&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25.2438&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SCENARIO 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Entity 1.TranTime&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I hope you enjoyed the package. Feel free to suggest new features and to contribute to its development!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introdução ao R - Aprendendo com o Moneyball</title>
      <link>/post/introducao-ao-r-aprendendo-com-o-moneyball/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/introducao-ao-r-aprendendo-com-o-moneyball/</guid>
      <description>&lt;p&gt;Este post corresponde aos slides do Mini-Curso “Introdução ao R - Aprendendo com o Moneyball”, realizado em 2017 no SIGEPRO. Cada um dos títulos neste post correspondia a um slide.&lt;/p&gt;
&lt;div id=&#34;o-que-veremos-neste-mini-curso&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;O que Veremos neste Mini-Curso?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;O que é Data Analytics?&lt;/li&gt;
&lt;li&gt;Exemplo Moneyball.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Como continuar aprendendo.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;porque-usar-o-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Porque usar o R ?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Open Source e Gratuito;&lt;/li&gt;
&lt;li&gt;Mais de 10 k bibliotecas gratuitas;&lt;/li&gt;
&lt;li&gt;Suporta muitos tipos de Análises;&lt;/li&gt;
&lt;li&gt;Conhecimento “cumulativo” e transferível a outros contextos.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;outras-alternativas-se-voce-nao-quiser-programar.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Outras alternativas se você não quiser programar.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Excel(?);&lt;/li&gt;
&lt;li&gt;Alteryx;&lt;/li&gt;
&lt;li&gt;Microsoft Azure;&lt;/li&gt;
&lt;li&gt;Tableu para Análises visuais mais simples;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;que-tipo-de-pessoa-usa-o-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Que tipo de pessoa usa o R?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;R Developer: “Um desenvolvedor R usa suas habilidades de programamação para manipular dados e construir ferramentas para para análise de Dados.”&lt;/li&gt;
&lt;li&gt;Data Scientist: “Um cientista de dados combina técnicas estatísticas e de machine learning com programação em R para analisar e interpretar dados complexos”.&lt;/li&gt;
&lt;li&gt;Data Analyst: Um Data Analyst traduz números em português claro. Um analista de dados interpreta dados das empresas e o usa para tomar melhores decisões.&lt;/li&gt;
&lt;li&gt;Analista Quantitativo: Na área financeira, uma analista quantitativo garante que portfolios de investimento estão balenceados e encontra novas oportunidades de trading, e avalia preços de ativos usando modelos matemáticos.
Fonte: &lt;a href=&#34;http://datacamp.com&#34; class=&#34;uri&#34;&gt;http://datacamp.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exemplo---moneyball&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exemplo - MoneyBall&lt;/h3&gt;
&lt;p&gt;Este exemplo usa dados relacionados ao filme “Moneyball” para apresentar a técnica de regressão linear com o R.
Este exercício e a ideia de usar o exemplo do Moneyball é baseda em uma aula do MIT, da plataforma Edx: &lt;a href=&#34;https://courses.edx.org/courses/course-v1:MITx+15.071x_3+1T2016/&#34; class=&#34;uri&#34;&gt;https://courses.edx.org/courses/course-v1:MITx+15.071x_3+1T2016/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moneyball-e-o-oakland-as&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Moneyball e o Oakland A’s&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Moneyball é o livro que conta a história sobre como o Data Analytics mudou a indústria do baseball;&lt;/li&gt;
&lt;li&gt;Oakland A’s: Um dos times mais pobres do baseball. Foi vendido e teve seu orçamento cortado;&lt;/li&gt;
&lt;li&gt;Em 2002 o time perdeu três jogadores principais (é desse ponto que o filme começa);&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;qual-e-a-meta-de-um-time-de-baseball&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Qual é a meta de um time de Baseball?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ir para as Playoffs!&lt;/li&gt;
&lt;li&gt;Quantos jogos um time precisa ganhar para chegar às playoffs?&lt;/li&gt;
&lt;li&gt;Paul DePodesta calculou que um time precisa de 95 vitórias para chegar às Playoffs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;como-se-vence-95-jogos&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Como se vence 95 jogos?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fazendo mais “Runs” do que o oponente.&lt;/li&gt;
&lt;li&gt;Quantos “Runs” a mais?&lt;/li&gt;
&lt;li&gt;Eles calcularam que precisariam fazer 135 Runs a mais do receberam para ganhar 95 jogos. Como calcular isso?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;lendo-dados-em-csv-com-read.csv&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Lendo Dados em CSV com read.csv()&lt;/h3&gt;
&lt;p&gt;Normalmente lemos dados no formato .csv no R para realizar as análises. É possível também ler dados em outros formatos. Obtenha &lt;a href=&#34;/post/2018-10-10-moneyball-r/baseball.csv&#34;&gt;aqui o arquivo baseball&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Lendo Dados em CSV
baseball &amp;lt;- read.csv(&amp;quot;2018-10-10-moneyball-r/baseball.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conhecendo-os-dados-com-str&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conhecendo os Dados com str()&lt;/h3&gt;
&lt;p&gt;Antes de rodar qualquer análise precisamos conhecer a estrutura dos dados.
Os dados contém uma linha para cada time e ano de 1962 a 2012 para todas as temporadas.
Dados incluem Runs Scored (RS), Runs Allowed (RA) e Vitórias (W).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Podemos fazer isso usando a função str() (que mostra a estrutura)
str(baseball)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    1232 obs. of  15 variables:
##  $ Team        : Factor w/ 39 levels &amp;quot;ANA&amp;quot;,&amp;quot;ARI&amp;quot;,&amp;quot;ATL&amp;quot;,..: 2 3 4 5 7 8 9 10 11 12 ...
##  $ League      : Factor w/ 2 levels &amp;quot;AL&amp;quot;,&amp;quot;NL&amp;quot;: 2 2 1 1 2 1 2 1 2 1 ...
##  $ Year        : int  2012 2012 2012 2012 2012 2012 2012 2012 2012 2012 ...
##  $ RS          : int  734 700 712 734 613 748 669 667 758 726 ...
##  $ RA          : int  688 600 705 806 759 676 588 845 890 670 ...
##  $ W           : int  81 94 93 69 61 85 97 68 64 88 ...
##  $ OBP         : num  0.328 0.32 0.311 0.315 0.302 0.318 0.315 0.324 0.33 0.335 ...
##  $ SLG         : num  0.418 0.389 0.417 0.415 0.378 0.422 0.411 0.381 0.436 0.422 ...
##  $ BA          : num  0.259 0.247 0.247 0.26 0.24 0.255 0.251 0.251 0.274 0.268 ...
##  $ Playoffs    : int  0 1 1 0 0 0 1 0 0 1 ...
##  $ RankSeason  : int  NA 4 5 NA NA NA 2 NA NA 6 ...
##  $ RankPlayoffs: int  NA 5 4 NA NA NA 4 NA NA 2 ...
##  $ G           : int  162 162 162 162 162 162 162 162 162 162 ...
##  $ OOBP        : num  0.317 0.306 0.315 0.331 0.335 0.319 0.305 0.336 0.357 0.314 ...
##  $ OSLG        : num  0.415 0.378 0.403 0.428 0.424 0.405 0.39 0.43 0.47 0.402 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;resumindo-com-o-summary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Resumindo com o summary()&lt;/h3&gt;
&lt;p&gt;Também podemos ter uma ideia dos dados usando o summary. Ele nos retorna médias, quartis, valores mínimos e máximos.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(baseball)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Team     League        Year            RS               RA        
##  BAL    : 47   AL:616   Min.   :1962   Min.   : 463.0   Min.   : 472.0  
##  BOS    : 47   NL:616   1st Qu.:1977   1st Qu.: 652.0   1st Qu.: 649.8  
##  CHC    : 47            Median :1989   Median : 711.0   Median : 709.0  
##  CHW    : 47            Mean   :1989   Mean   : 715.1   Mean   : 715.1  
##  CIN    : 47            3rd Qu.:2002   3rd Qu.: 775.0   3rd Qu.: 774.2  
##  CLE    : 47            Max.   :2012   Max.   :1009.0   Max.   :1103.0  
##  (Other):950                                                            
##        W              OBP              SLG               BA        
##  Min.   : 40.0   Min.   :0.2770   Min.   :0.3010   Min.   :0.2140  
##  1st Qu.: 73.0   1st Qu.:0.3170   1st Qu.:0.3750   1st Qu.:0.2510  
##  Median : 81.0   Median :0.3260   Median :0.3960   Median :0.2600  
##  Mean   : 80.9   Mean   :0.3263   Mean   :0.3973   Mean   :0.2593  
##  3rd Qu.: 89.0   3rd Qu.:0.3370   3rd Qu.:0.4210   3rd Qu.:0.2680  
##  Max.   :116.0   Max.   :0.3730   Max.   :0.4910   Max.   :0.2940  
##                                                                    
##     Playoffs        RankSeason     RankPlayoffs         G        
##  Min.   :0.0000   Min.   :1.000   Min.   :1.000   Min.   :158.0  
##  1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:162.0  
##  Median :0.0000   Median :3.000   Median :3.000   Median :162.0  
##  Mean   :0.1981   Mean   :3.123   Mean   :2.717   Mean   :161.9  
##  3rd Qu.:0.0000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:162.0  
##  Max.   :1.0000   Max.   :8.000   Max.   :5.000   Max.   :165.0  
##                   NA&amp;#39;s   :988     NA&amp;#39;s   :988                    
##       OOBP             OSLG       
##  Min.   :0.2940   Min.   :0.3460  
##  1st Qu.:0.3210   1st Qu.:0.4010  
##  Median :0.3310   Median :0.4190  
##  Mean   :0.3323   Mean   :0.4197  
##  3rd Qu.:0.3430   3rd Qu.:0.4380  
##  Max.   :0.3840   Max.   :0.4990  
##  NA&amp;#39;s   :812      NA&amp;#39;s   :812&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;acessando-variaveis-especificas-de-um-dataframe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Acessando variáveis específicas de um DataFrame&lt;/h3&gt;
&lt;p&gt;Podemos acessar variáveis específicas de um Data Frame usando algumas notações possíveis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(baseball$Year)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2012 2012 2012 2012 2012 2012&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;selecionando-linhas-especificas-do-df&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Selecionando Linhas Específicas do DF&lt;/h3&gt;
&lt;p&gt;Vamos selecionar apenas dados até o ano de 2002 (que foram os dados que eles possuíam em 2002)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Considerando apenas anos exibidos pelo moneyball
moneyball = subset(baseball, Year &amp;lt; 2002)
str(moneyball)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    902 obs. of  15 variables:
##  $ Team        : Factor w/ 39 levels &amp;quot;ANA&amp;quot;,&amp;quot;ARI&amp;quot;,&amp;quot;ATL&amp;quot;,..: 1 2 3 4 5 7 8 9 10 11 ...
##  $ League      : Factor w/ 2 levels &amp;quot;AL&amp;quot;,&amp;quot;NL&amp;quot;: 1 2 2 1 1 2 1 2 1 2 ...
##  $ Year        : int  2001 2001 2001 2001 2001 2001 2001 2001 2001 2001 ...
##  $ RS          : int  691 818 729 687 772 777 798 735 897 923 ...
##  $ RA          : int  730 677 643 829 745 701 795 850 821 906 ...
##  $ W           : int  75 92 88 63 82 88 83 66 91 73 ...
##  $ OBP         : num  0.327 0.341 0.324 0.319 0.334 0.336 0.334 0.324 0.35 0.354 ...
##  $ SLG         : num  0.405 0.442 0.412 0.38 0.439 0.43 0.451 0.419 0.458 0.483 ...
##  $ BA          : num  0.261 0.267 0.26 0.248 0.266 0.261 0.268 0.262 0.278 0.292 ...
##  $ Playoffs    : int  0 1 1 0 0 0 0 0 1 0 ...
##  $ RankSeason  : int  NA 5 7 NA NA NA NA NA 6 NA ...
##  $ RankPlayoffs: int  NA 1 3 NA NA NA NA NA 4 NA ...
##  $ G           : int  162 162 162 162 161 162 162 162 162 162 ...
##  $ OOBP        : num  0.331 0.311 0.314 0.337 0.329 0.321 0.334 0.341 0.341 0.35 ...
##  $ OSLG        : num  0.412 0.404 0.384 0.439 0.393 0.398 0.427 0.455 0.417 0.48 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;relembrando-nosso-objetivo&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Relembrando nosso objetivo&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Objetivo: Saber como chegar às playoffs.&lt;/li&gt;
&lt;li&gt;Em outras Palavras: Saber quantos Runs um time deve fazer a mais do que “leva” para ter mais do que 95 vitórias.&lt;/li&gt;
&lt;li&gt;Como: Usando uma Regressão Linear para predizer Vitórias em função do Run Differences.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;calculando-a-run-difference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculando a RUN Difference&lt;/h3&gt;
&lt;p&gt;Criando uma nova variável para calcular a “Run Difference”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculando a Run Difference
moneyball$RD = moneyball$RS - moneyball$RA
str(moneyball)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    902 obs. of  16 variables:
##  $ Team        : Factor w/ 39 levels &amp;quot;ANA&amp;quot;,&amp;quot;ARI&amp;quot;,&amp;quot;ATL&amp;quot;,..: 1 2 3 4 5 7 8 9 10 11 ...
##  $ League      : Factor w/ 2 levels &amp;quot;AL&amp;quot;,&amp;quot;NL&amp;quot;: 1 2 2 1 1 2 1 2 1 2 ...
##  $ Year        : int  2001 2001 2001 2001 2001 2001 2001 2001 2001 2001 ...
##  $ RS          : int  691 818 729 687 772 777 798 735 897 923 ...
##  $ RA          : int  730 677 643 829 745 701 795 850 821 906 ...
##  $ W           : int  75 92 88 63 82 88 83 66 91 73 ...
##  $ OBP         : num  0.327 0.341 0.324 0.319 0.334 0.336 0.334 0.324 0.35 0.354 ...
##  $ SLG         : num  0.405 0.442 0.412 0.38 0.439 0.43 0.451 0.419 0.458 0.483 ...
##  $ BA          : num  0.261 0.267 0.26 0.248 0.266 0.261 0.268 0.262 0.278 0.292 ...
##  $ Playoffs    : int  0 1 1 0 0 0 0 0 1 0 ...
##  $ RankSeason  : int  NA 5 7 NA NA NA NA NA 6 NA ...
##  $ RankPlayoffs: int  NA 1 3 NA NA NA NA NA 4 NA ...
##  $ G           : int  162 162 162 162 161 162 162 162 162 162 ...
##  $ OOBP        : num  0.331 0.311 0.314 0.337 0.329 0.321 0.334 0.341 0.341 0.35 ...
##  $ OSLG        : num  0.412 0.404 0.384 0.439 0.393 0.398 0.427 0.455 0.417 0.48 ...
##  $ RD          : int  -39 141 86 -142 27 76 3 -115 76 17 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;existe-uma-relacao-entre-run-difference-e-vitorias&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Existe uma Relação entre Run Difference e Vitórias?&lt;/h3&gt;
&lt;p&gt;Só faz sentido usar uma regressão linear se é plausível a existência de uma relação linear entre as variáveis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(moneyball$RD, moneyball$W, main = &amp;quot;Vitórias vs Runs Diff.&amp;quot;, xlab = &amp;quot;Run. Diff.&amp;quot;, ylab = &amp;quot;Vitórias&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-10-10-introducao-ao-r-aprendendo-com-o-moneyball_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;realizando-um-teste-de-correlacao&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Realizando um teste de Correlação&lt;/h3&gt;
&lt;p&gt;Existe uma correlação alta entre estas duas variáveis?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x = moneyball$RD, y = moneyball$W, method=c(&amp;quot;pearson&amp;quot;, &amp;quot;kendall&amp;quot;, &amp;quot;spearman&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.938515&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(x = moneyball$RD, y = moneyball$W, method=c(&amp;quot;pearson&amp;quot;, &amp;quot;kendall&amp;quot;, &amp;quot;spearman&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  moneyball$RD and moneyball$W
## t = 81.554, df = 900, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.9302271 0.9458460
## sample estimates:
##      cor 
## 0.938515&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizando-a-correlacao-entre-as-duas-variaveis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizando a Correlação entre as duas variáveis&lt;/h3&gt;
&lt;p&gt;Também podemos visualizar que existe uma correlação alta entre estas duas variáveis utilizando gráficos da biblioteca ggpubr.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggpubr::ggscatter(moneyball, x = &amp;quot;RD&amp;quot;, y = &amp;quot;W&amp;quot;,
          add = &amp;quot;reg.line&amp;quot;, conf.int = TRUE,
          cor.coef = TRUE, cor.method = &amp;quot;pearson&amp;quot;,
          xlab = &amp;quot;Run Diff.&amp;quot;, ylab = &amp;quot;Vitórias&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-10-10-introducao-ao-r-aprendendo-com-o-moneyball_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ok-como-predizer-o-numero-de-vitorias-com-base-em-run-differences&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ok, como predizer o número de vitórias com base em Run Differences?&lt;/h3&gt;
&lt;p&gt;Usando uma Regressão Linear!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y = \beta_0 + \beta_1 * x + e\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ou, em outras palavras…&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Vitorias = \beta_0 + \beta_1 * RunDiffs + e\]&lt;/span&gt;
Como fazer isso no R?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelo_vitorias = lm(W ~ RD, data=moneyball)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;analisando-o-modelo-para-predizer-vitorias&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Analisando o Modelo para Predizer Vitórias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;O que isso significa: Podemos predizer o número de vitórias que um time terá a partir de um número de Home Runs.
&lt;span class=&#34;math display&#34;&gt;\[ Vitorias = 80.88 + 0.1057 RunDiffs\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(modelo_vitorias)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = W ~ RD, data = moneyball)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.2662  -2.6509   0.1234   2.9364  11.6570 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 80.881375   0.131157  616.67   &amp;lt;2e-16 ***
## RD           0.105766   0.001297   81.55   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 3.939 on 900 degrees of freedom
## Multiple R-squared:  0.8808, Adjusted R-squared:  0.8807 
## F-statistic:  6651 on 1 and 900 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;sera-que-e-sao-necessarios-135-runs-a-mais-para-chegar-a-playoffs&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Será que é são necessários 135 Runs a mais para chegar à Playoffs?&lt;/h3&gt;
&lt;p&gt;A partir da regressão linear nós estimamos que $ Vitorias = 80.88 + 0.1057 RunDiffs$ e também sabemos que &lt;span class=&#34;math inline&#34;&gt;\(Vitorias &amp;gt;= 95\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Então…&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ 80.88 + 0.1057 RunDiffs &amp;gt;= 95\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;E…&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[RunDiffs &amp;gt;= \frac{95 - 80.8814}{0.1058} &amp;gt;= 133,446\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ou, já que estamos no R…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RD_min = (95 - 80.8814)/0.1058
RD_min&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 133.4461&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OU seja, sabemos que se um time quer ir para as playoffs ele precisa fazer &lt;strong&gt;133,4&lt;/strong&gt; Runs a mais do que seus oponentes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;o-que-temos-ate-agora&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;O que temos até Agora&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Para ir para as playoffs o time precisa de 95 vitórias ou mais.&lt;/li&gt;
&lt;li&gt;Para ter 95 vitórias, o time precisa de 133 ~ 135 Runs a mais do que os oponentes.&lt;/li&gt;
&lt;li&gt;Para isso, o time precisa:
– Fazer mais Runs.
– Levar menos Runs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;como-avaliar-um-jogador&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Como Avaliar um Jogador?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Percentual de Rebatidas? (Batting Average - BA)&lt;/li&gt;
&lt;li&gt;Percentual de tempo que o Jogador passa na Base? (incluindo walks) (On-Base Percentage);&lt;/li&gt;
&lt;li&gt;Slugging Percentage (SLG). O quão longe um jogador chega na sua vez de rebater;&lt;/li&gt;
&lt;li&gt;Quais destas estatísticas são mais importantes para considerar quando é necessário &lt;strong&gt;comprar um jogador&lt;/strong&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;recorrendo-a-regressao-linear-novamente&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Recorrendo à Regressão Linear Novamente!&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Na nossa base de dados estas estatísticas estão indicadas nas variáveis RS (Runs Scored), On-Base Percentage (OBP), Slugging Percentage (SLG) e Batting Average (BA).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(moneyball)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    902 obs. of  16 variables:
##  $ Team        : Factor w/ 39 levels &amp;quot;ANA&amp;quot;,&amp;quot;ARI&amp;quot;,&amp;quot;ATL&amp;quot;,..: 1 2 3 4 5 7 8 9 10 11 ...
##  $ League      : Factor w/ 2 levels &amp;quot;AL&amp;quot;,&amp;quot;NL&amp;quot;: 1 2 2 1 1 2 1 2 1 2 ...
##  $ Year        : int  2001 2001 2001 2001 2001 2001 2001 2001 2001 2001 ...
##  $ RS          : int  691 818 729 687 772 777 798 735 897 923 ...
##  $ RA          : int  730 677 643 829 745 701 795 850 821 906 ...
##  $ W           : int  75 92 88 63 82 88 83 66 91 73 ...
##  $ OBP         : num  0.327 0.341 0.324 0.319 0.334 0.336 0.334 0.324 0.35 0.354 ...
##  $ SLG         : num  0.405 0.442 0.412 0.38 0.439 0.43 0.451 0.419 0.458 0.483 ...
##  $ BA          : num  0.261 0.267 0.26 0.248 0.266 0.261 0.268 0.262 0.278 0.292 ...
##  $ Playoffs    : int  0 1 1 0 0 0 0 0 1 0 ...
##  $ RankSeason  : int  NA 5 7 NA NA NA NA NA 6 NA ...
##  $ RankPlayoffs: int  NA 1 3 NA NA NA NA NA 4 NA ...
##  $ G           : int  162 162 162 162 161 162 162 162 162 162 ...
##  $ OOBP        : num  0.331 0.311 0.314 0.337 0.329 0.321 0.334 0.341 0.341 0.35 ...
##  $ OSLG        : num  0.412 0.404 0.384 0.439 0.393 0.398 0.427 0.455 0.417 0.48 ...
##  $ RD          : int  -39 141 86 -142 27 76 3 -115 76 17 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;predizendo-o-numero-de-runs---modelo-completo&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Predizendo o Número de Runs - Modelo Completo&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Quanto menos Batting Average, mais Runs?!&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modeloruns = lm(formula = RS ~ OBP + SLG + BA, data=moneyball)
summary(modeloruns)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = RS ~ OBP + SLG + BA, data = moneyball)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -70.941 -17.247  -0.621  16.754  90.998 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  -788.46      19.70 -40.029  &amp;lt; 2e-16 ***
## OBP          2917.42     110.47  26.410  &amp;lt; 2e-16 ***
## SLG          1637.93      45.99  35.612  &amp;lt; 2e-16 ***
## BA           -368.97     130.58  -2.826  0.00482 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 24.69 on 898 degrees of freedom
## Multiple R-squared:  0.9302, Adjusted R-squared:   0.93 
## F-statistic:  3989 on 3 and 898 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;predizendo-o-numero-de-runs---sem-batting-average&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Predizendo o Número de Runs - Sem Batting Average&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;O modelo mais simples tem menos variáveis e ainda tem um R ao quadrado alto.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Runs = -804.3 + 2737.77 * OBP + 1584.91 * SLG\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modeloruns_sBA = lm(formula = RS ~ OBP + SLG, data=moneyball)
summary(modeloruns_sBA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = RS ~ OBP + SLG, data = moneyball)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -70.838 -17.174  -1.108  16.770  90.036 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  -804.63      18.92  -42.53   &amp;lt;2e-16 ***
## OBP          2737.77      90.68   30.19   &amp;lt;2e-16 ***
## SLG          1584.91      42.16   37.60   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 24.79 on 899 degrees of freedom
## Multiple R-squared:  0.9296, Adjusted R-squared:  0.9294 
## F-statistic:  5934 on 2 and 899 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;predizendo-o-numero-de-runs-allowed&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Predizendo o Número de Runs Allowed&lt;/h3&gt;
&lt;p&gt;Com essa regressão, podemos estimar as Runs Permitidas com a equação:
&lt;span class=&#34;math display&#34;&gt;\[ Runs Permitidas = -837 + 2913.6 * OOBP + 1514.29 * OSLG\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelorunsallowed = lm(formula = RA ~ OOBP + OSLG, data=moneyball)
summary(modelorunsallowed)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = RA ~ OOBP + OSLG, data = moneyball)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -82.397 -15.178  -0.129  17.679  60.955 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  -837.38      60.26 -13.897  &amp;lt; 2e-16 ***
## OOBP         2913.60     291.97   9.979 4.46e-16 ***
## OSLG         1514.29     175.43   8.632 2.55e-13 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 25.67 on 87 degrees of freedom
##   (812 observations deleted due to missingness)
## Multiple R-squared:  0.9073, Adjusted R-squared:  0.9052 
## F-statistic: 425.8 on 2 and 87 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;agora-vem-a-parte-legal&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Agora vem a parte legal&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Com os nossos modelos, agora é possível tentar predizer quantos jogos o Oakland A’s vai ganhar em um determinado ano.&lt;/li&gt;
&lt;li&gt;Estamos tentando predizer quantos jogos o time vai ganhar &lt;strong&gt;antes&lt;/strong&gt; da temporada começar, com o objetivo de suportar a decisão sobre &lt;strong&gt;quais jogadores&lt;/strong&gt; queremos comprar.&lt;/li&gt;
&lt;li&gt;Pressuposto # 1: Performance passada dos jogadores do time que estamos montando tem correlação com a performance futura.&lt;/li&gt;
&lt;li&gt;Pressuposto # 2: A análise assume que haverão poucas lesões.&lt;/li&gt;
&lt;li&gt;Pressuposto # 3: Podemos estimar estatísticas para 2002 usando estatísticas dos jogadores coletadas em 2001.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;estimando-runs-para-2002&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimando Runs para 2002&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Com base na temporada de 2001, com o grupo que tivemos sabemos que a média do OBP é 0.339, e do SLG é 0.430.&lt;/li&gt;
&lt;li&gt;Nossa Regressão para Runs foi $ Runs = -804.3 + 2737.77 * OBP + 1584.91 * SLG$.&lt;/li&gt;
&lt;li&gt;Então a Estimativa de Runs é..&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Runs = -804.3 + 2737.77 * 0.339 + 1584.91 *  0.430
Runs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 805.3153&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimando-runs-allowed-para-2002&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimando Runs Allowed para 2002&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Com base na temporada de 2001, com o grupo que tivemos sabemos que a média do OOBP é 0.307, e do OSLG é 0.373.&lt;/li&gt;
&lt;li&gt;Nossa Regressão para Runs foi $ Runs Permitidas = -837 + 2913.6 * OOBP + 1514.29 * OSLG$.&lt;/li&gt;
&lt;li&gt;Podemos fazer o mesmo para Runs Allowed&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RunsAllowed = -837 + 2913.6 * 0.307 + 1514.29 * 0.373
RunsAllowed&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 622.3054&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quantos-jogos-esperamos-ganhar-com-esse-time&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Quantos Jogos Esperamos Ganhar com esse Time?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nosso modelo de vitórias diz que $ Vitorias = 80.88 + 0.1057 RunDiffs$. Então..&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Vitorias = 80.88 + 0.1057 * (Runs - RunsAllowed)
if (Vitorias &amp;gt;= 95) {
  paste(&amp;quot;Esse time deve chegar nas Playoffs com &amp;quot;, Vitorias, &amp;quot; vitórias.&amp;quot;)
} else {
  paste(&amp;quot;Compre outros Jogadores, este time não chega nas playoffs com apenas &amp;quot;, Vitorias, &amp;quot; vitórias!&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Esse time deve chegar nas Playoffs com  100.224152772  vitórias.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A abordagem de Paul foi parecida com essa.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;a-hora-da-verdade&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A hora da verdade&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nosso modelo serve para alguma coisa?&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Variável&lt;/th&gt;
&lt;th&gt;Nosso Modelo&lt;/th&gt;
&lt;th&gt;Modelo do Paul&lt;/th&gt;
&lt;th&gt;Realizado&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Runs&lt;/td&gt;
&lt;td&gt;805&lt;/td&gt;
&lt;td&gt;800 - 820&lt;/td&gt;
&lt;td&gt;800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Runs Allowed&lt;/td&gt;
&lt;td&gt;622&lt;/td&gt;
&lt;td&gt;650 - 670&lt;/td&gt;
&lt;td&gt;653&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Vitórias&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;93 - 97&lt;/td&gt;
&lt;td&gt;103&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;O Oakland A’s ganhou 20 jogos em sequência nesse ano, mas não ganhou o campeonato;&lt;/li&gt;
&lt;li&gt;O Oakland A’s conseguiu ir para as Playoffs mais uma vez!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;como-aprender-mais&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Como Aprender Mais?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;github.com;&lt;/li&gt;
&lt;li&gt;datacamp.com;&lt;/li&gt;
&lt;li&gt;stackoverflow.com;&lt;/li&gt;
&lt;li&gt;udacity.com;&lt;/li&gt;
&lt;li&gt;edx.org;&lt;/li&gt;
&lt;li&gt;coursera.org;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>