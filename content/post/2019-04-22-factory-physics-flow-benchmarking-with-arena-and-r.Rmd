---
title: Factory Physics' Flow Benchmarking in R
author: Pedro N. de Lima
date: '2019-04-22'
slug: factory-physics-flow-benchmarking-in-r
categories:
  - R Blogs
  - R
tags:
  - R
  - Simulation
header:
  caption: ''
  image: ''
bibliography: [references/references-metamodeling.bib]
link-citations: true
---

[Flow Benchmarking](https://factoryphysics.com/flow-benchmarking) is an absolute benchmarking technique that allows one to visualize the performance limits of a manufacturing system in terms of Work in Process, Throughput and Cycle Time. This technique has been introduced in the award-winning *Factory Physics* (FP) Book [@hopp2008factory], and is a key component of the science-based manufacturing management approach described in [@pound2014factory]. This post will use [R](https://www.r-project.org/) to allow one to quickly run this analysis using the Basic Factory Dynamics equations found in the original FP books.

## Defining FP Laws

The Flow Benchmarking analysis is grounded on Little's Law (WIP = TH * CT), and utilizes three general cases as absolute benchmarks for any real manufacturing system: The **Best Case**, the **Worst Case** and the **Practical Worst Case** .Please refer to [@hopp2008factory] and [@pound2014factory] for the rationale for these laws and equations. 

I'll define these equations as R functions:

```{r FP_Laws}

calc_w0 = function(rb, t0) {rb * t0}

ct_best = function(t0, w, w0, rb) {ifelse(w<=w0,t0,w/rb)}

th_best = function(t0, w, w0, rb) {ifelse(w<=w0,w/t0,rb)}

ct_worst = function(w,t0){w*t0}

th_worst = function(t0){1/t0}

ct_marginal = function(t0,w,rb){t0+(w-1)/rb}

th_marginal = function(w0,w,rb){rb*w/(w0+w-1)}

```

In summary, these equations provide a starting point to discuss how well a manufacturing system is doing in terms of converting inventory to Throughput. The initial analysis requires two inputs. The first input is the **Bottleneck rate (rb)**, which is the production rate (parts, orders / time) of the bottleneck (defined as the process center with the highest long-term utilization). The second parameter is the **Total Raw Processing Time (t0)**, which is the sum of the long-term average process times of each processing center. Based on these two parameters, its possible to draw benchmarking curves for the System's Throughput and Cycle Time as a function of its Work in Process, assuming a CONWIP control system [@Spearman1990].

## Drawing Benchmarking Curves

Once I have the basic laws of manufacturing dynamics as R functions, I'll create a `benchmarck_flow` function to execute the analysis. This function accepts the `rb` and `t0` parameters and will calculate the system's Throughput and Cycle time as a function of the wip under different scenarios for benchmarking purposes.

```{r}

## Defining Cycle time and Throughput functions

benchmark_flow = function(rb, t0, step = 1, wip_mult = 5) {
  
  # First, calculate wip_crit
  w0 = calc_w0(rb = rb, t0 = t0)
  
  # Then, define WIP Range to consider:
  wip = seq.int(from = 1, to = w0 * wip_mult, by = step)
  
  # Then, calculate The Best Case Variables
  Best_Cycle_Time = ct_best(t0 = t0, w = wip, w0 = w0, rb = rb)
  Best_Throughput = th_best(t0 = t0, w = wip, w0 = w0, rb = rb)
  
  best_data = data.frame(WIP = wip,
                    Throughput = Best_Throughput,
                    CycleTime = Best_Cycle_Time,
                    Scenario = "Best Case")
  
  # Calculate the Marginal Cases:
  Marginal_Cycle_Time = ct_marginal(t0=t0,w=wip,rb=rb)
  Marginal_Throughput = th_marginal(w0=w0,w=wip,rb=rb)
  
  marginal_data = data.frame(WIP = wip,
                    Throughput = Marginal_Throughput,
                    CycleTime = Marginal_Cycle_Time,
                    Scenario = "Marginal")
  
  # Calculate Worst Case
  worst_data = data.frame(
    WIP = wip,
    Throughput = th_worst(t0 = t0),
    CycleTime = ct_worst(w = wip, t0 = t0),
    Scenario = "Worst Case"
  )

  # Output A DataFrame with results:
  # I'm not including the Worst Case because it's unrealistic (and messes up my cycle time plot).
  rbind(best_data, marginal_data, worst_data)
  
}

# The First Penny Fab Example:
data_benchmark = benchmark_flow(rb = 0.5, t0 = 8)

knitr::kable(head(data_benchmark))
```

Ok, now I have a table with all the benchmarking results, let's plot it!

```{r factory-physics-flow-benchmarking-cycletime-wip-throughput-plot}
library(tidyr)
library(ggplot2)
library(viridis)

# Lets define a wrapper function for our plot:

plot_benchmarking = function(data) {
  data %>%
    gather(-WIP, -Scenario, key = "var", value = "Value") %>%
  ggplot(aes(x = WIP, y = Value, color = Scenario)) +
    geom_line(size = 1) +
    facet_wrap(~ var, scales = "free", nrow = 2, ncol = 1) +
    labs(title = "Flow Benchmarking Plot") +
    scale_color_viridis(discrete = TRUE, option = "D") + 
    theme_bw()
}

# Then let's just benchmark and plot!

plot_benchmarking(data = benchmark_flow(rb = 0.5, t0 = 8, wip_mult = 5))
  

```

After plotting the benchmarking curves, compare the curves with the system's actual condition (mark an "x" indicating the system's actual WIP, Cycle Time and Throughput), and have a productive discussion about how to improve it. Again, I suggest you to read the [@pound2014factory] book to understand the many uses of this plot.

If you would like to perform a more detailed analysis of a complex system, it's possible to use a Simulation Model of the actual system, and plot the results from Simulation Runs (you would see a another line on these plots). Doing this would allow you to gain predictive insight of where the system **will be** if you add WIP or make improvements.

# References



