---
title: Factory Physics' Flow Benchmarking in R (with Metamodeling)
author: Pedro N. de Lima
date: '2019-04-20'
slug: factory-physics-flow-benchmarking-in-r
categories:
  - R Blogs
  - R
tags:
  - R
  - Simulation
  - Arena
  - Arena2r
header:
  caption: ''
  image: ''
bibliography: [references/references-metamodeling.bib]
link-citations: true
---

[Flow Benchmarking](https://factoryphysics.com/flow-benchmarking) is an absolute benchmarking technique that allows one to compare the current performance of a manufacturing system against its performance limits in terms of Work in Process, Throughput and Cycle Time. The technique has been introduced in the award-winning *Factory Physics* (FP) Book [@hopp2008factory], and is a key component of the science-based manufacturing management approach described in [@pound2014factory]. This post will use [R](https://www.r-project.org/) to allow one to quickly run this analysis using the Basic Factory Dynamics equations found in the original FP books. I'll also build on [my previous posts on metamodeling](/post/des-metamodeling-splines-r-arena/) to illustrate how they can be used to support a factory physics approach to flow benchmarking.

## Defining Factory Physics Laws

The Flow Benchmarking analysis is grounded on Little's Law (WIP = TH * CT), and utilizes three general cases as absolute benchmarks for any real manufacturing system: The **Best Case**, the **Worst Case** and the **Practical Worst Case** .Please refer to [@hopp2008factory] and [@pound2014factory] for the rationale for these laws and equations. 

I'll define these equations as R functions:

```{r FP_Laws}

calc_w0 = function(rb, t0) {rb * t0}

ct_best = function(t0, w, w0, rb) {ifelse(w<=w0,t0,w/rb)}

th_best = function(t0, w, w0, rb) {ifelse(w<=w0,w/t0,rb)}

ct_worst = function(w,t0){w*t0}

th_worst = function(t0){1/t0}

ct_marginal = function(t0,w,rb){t0+(w-1)/rb}

th_marginal = function(w0,w,rb){rb*w/(w0+w-1)}

```

In summary, these equations provide a starting point to discuss how well a manufacturing system is doing in terms of converting inventory to Throughput. The initial analysis requires two inputs. The first input is the **Bottleneck rate (rb)**, which is the production rate (parts, orders / time) of the bottleneck (defined as the process center with the highest long-term utilization). The second parameter is the **Total Raw Processing Time (t0)**, which is the sum of the long-term average process times of each processing center. Based on these two parameters, its possible to draw benchmarking curves for the System's Throughput and Cycle Time as a function of its Work in Process, assuming a CONWIP control system [@Spearman1990].

## Drawing Benchmarking Curves

Once I have the basic laws of manufacturing dynamics as R functions, I'll create a `benchmarck_flow` function to execute the analysis. This function accepts the `rb` and `t0` parameters and will calculate the system's Throughput and Cycle time as a function of the wip under different scenarios for benchmarking purposes.

```{r}

## Defining Cycle time and Throughput functions

benchmark_flow = function(rb, t0, step = 1, wip_mult = 5) {
  
  # First, calculate wip_crit
  w0 = calc_w0(rb = rb, t0 = t0)
  
  # Then, define WIP Range to consider:
  wip = seq.int(from = 1, to = w0 * wip_mult, by = step)
  
  # Then, calculate The Best Case Variables
  Best_Cycle_Time = ct_best(t0 = t0, w = wip, w0 = w0, rb = rb)
  Best_Throughput = th_best(t0 = t0, w = wip, w0 = w0, rb = rb)
  
  best_data = data.frame(WIP = wip,
                    Throughput = Best_Throughput,
                    CycleTime = Best_Cycle_Time,
                    Scenario = "Best Case")
  
  # Calculate the Marginal Cases:
  Marginal_Cycle_Time = ct_marginal(t0=t0,w=wip,rb=rb)
  Marginal_Throughput = th_marginal(w0=w0,w=wip,rb=rb)
  
  marginal_data = data.frame(WIP = wip,
                    Throughput = Marginal_Throughput,
                    CycleTime = Marginal_Cycle_Time,
                    Scenario = "Marginal")
  
  # Calculate Worst Case
  worst_data = data.frame(
    WIP = wip,
    Throughput = th_worst(t0 = t0),
    CycleTime = ct_worst(w = wip, t0 = t0),
    Scenario = "Worst Case"
  )

  # Output A DataFrame with results:
  # I'm not including the Worst Case because it's unrealistic (and messes up my cycle time plot).
  rbind(best_data, marginal_data, worst_data)
  
}

# The First Penny Fab Example:
data_benchmark = benchmark_flow(rb = 0.5, t0 = 8)

knitr::kable(head(data_benchmark))
```


# How would the Actual System Behave? Simulation Metamodeling comes in
Ok, now I have a table with all the basic benchmarking results. What if I have a better model of the system? (e.g., a Discrete Event Model or a better queueing model). We can accomplish this by building a discrete event simulation model of the actual system, and using a [spline metamodel](/post/post/des-metamodeling-splines-r-arena/) of this model approximate its results.

```{r simulation-model}


library(arena2r)
library(tidyr)
arena_data = arena2r::get_simulation_results("2019-data/penny-fab")

# Filtering only Statistics of our Interest:

filtered_data = subset(arena_data, Statistic %in% c("w", "LeadTime", "Throughput"))

# Spreading and Data Wrangling

final_data = filtered_data %>% 
  tidyr::spread(Statistic, Value) %>%
  dplyr::select(LeadTime, Throughput, w)

colnames(final_data) = c("CycleTime", "Throughput", "WIP")

# Now, build a spline metamodel for CycleTime and Throughput as a function of WIP.

th_model = lm(Throughput ~ splines::bs(WIP), data = final_data)

ct_model = lm(CycleTime ~ WIP, data = final_data)

# Put Together a Final DataFrame like the Benchmarking:

model_data = data.frame(
  WIP = unique(data_benchmark$WIP),
  Throughput = predict(th_model, subset(data_benchmark, Scenario == "Best Case")),
  CycleTime = predict(ct_model, subset(data_benchmark, Scenario == "Best Case")),
  Scenario = "DES Model"
)

# Adding our Model's Data to the DataFrame:

data_benchmark = rbind(
  data_benchmark,
  model_data
)


```

Now, let's plot it!

```{r factory-physics-flow-benchmarking-cycletime-wip-throughput-plot}
library(tidyr)
library(ggplot2)
library(viridis)

# Lets define a wrapper function for our plot:

plot_benchmarking = function(data) {
  data %>%
    gather(-WIP, -Scenario, key = "var", value = "Value") %>%
  ggplot(aes(x = WIP, y = Value, color = Scenario)) +
    geom_line(size = 1) +
    facet_wrap(~ var, scales = "free", nrow = 2, ncol = 1) +
    labs(title = "Flow Benchmarking Plot") +
    scale_color_viridis(discrete = TRUE, option = "D") + 
    theme_bw()
}

# Then let's just benchmark and plot!

plot_benchmarking(data = data_benchmark)
  

```

Cool! My simulation model is quite equivalent to the marginal case.

## Final Thoughts

After plotting the benchmarking curves, compare the curves with the system's actual condition (mark an "x" indicating the system's actual WIP, Cycle Time and Throughput), and have a productive discussion about how to improve it. Again, I suggest you to read the [@pound2014factory] book to understand the many uses of this plot.

As I demonstrated, using a metamodel is interesting because you can have more confidence that the system will behave as expected *if* you decide to reduce or increase WIP, for instance. In this particular case, the model behavior roughly maches the Marginal Case behavior, but this may not be the case in the real system. In case the system currently performs worse than the Marginal Case, the model can be used to simulate different improvement scenarios, and how they push the system towards the benchmark curves. Doing this would allow you to gain predictive insight of where the system **will be** if you add WIP or make improvements.



# References



